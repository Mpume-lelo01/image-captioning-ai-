#  Image Captioning AI
A deep learning project that generates human-like captions for images using computer vision and natural language processing (NLP). This tool automatically interprets the content of an image and produces descriptive text using pre-trained models.

##  Project Overview
The Image Captioning AI takes an image as input and returns a relevant, grammatically correct caption. Built as part of CAPACITI's AI bootcamp, the project explores how convolutional neural networks (CNNs) and language models can work together in vision-language tasks.

##  How It Works
-  Feature extraction using CNN (e.g. VGG16, ResNet)
-  Text generation with LSTM/Transformer-based decoder
- Accepts user-uploaded images and generates captions in real time

##  Tech Stack
- Python (Core language)
- TensorFlow / Keras (Deep learning)
- Flask / Streamlit (Web interface)
- OpenCV / PIL (Image processing)
- Jupyter Notebook / Google Colab

##  Features
- Upload an image and receive a smart, descriptive caption
- Uses pre-trained CNN and language model
- Clean UI for testing and demo
- Useful in accessibility, media tagging, and automation


## Folder Structure
image-captioning-ai/
├── model/ # Saved model weights
├── notebooks/ # Training & evaluation notebooks
├── app.py # Flask or Streamlit app
├── utils.py # Helper functions
├── requirements.txt
└── README.md


## Key Learnings
- Combined image understanding with language generation
- Improved knowledge of encoder-decoder architecture
- Experimented with transfer learning (CNNs)
- Learned to deploy AI apps using Streamlit/Flask

##  Responsible AI Note
- Captions are generated automatically and may reflect dataset bias
- This tool is for educational and prototyping use only

## Contact
Created by **Nompumelelo Mkhabela**  
[LinkedIn](https://www.linkedin.com/in/nompumelelo-mkhabela-8aa563247) • [GitHub](https://github.com/Mpume-lelo01)
